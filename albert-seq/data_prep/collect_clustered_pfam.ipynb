{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_cluster_size=10 #clusters with fewer than this won't be re-calculated; use original pfam consensus instead\n",
    "ncpus=48\n",
    "max_seq_len=253\n",
    "gapchar='j'\n",
    "padchar='9'\n",
    "basedir='/data/saturn/a/hlim/pfam_clustered_corpora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum62 = {\n",
    "    ('W', 'F'): 1, ('L', 'R'): -2, ('S', 'P'): -1, ('V', 'T'): 0,\n",
    "    ('Q', 'Q'): 5, ('N', 'A'): -2, ('Z', 'Y'): -2, ('W', 'R'): -3,\n",
    "    ('Q', 'A'): -1, ('S', 'D'): 0, ('H', 'H'): 8, ('S', 'H'): -1,\n",
    "    ('H', 'D'): -1, ('L', 'N'): -3, ('W', 'A'): -3, ('Y', 'M'): -1,\n",
    "    ('G', 'R'): -2, ('Y', 'I'): -1, ('Y', 'E'): -2, ('B', 'Y'): -3,\n",
    "    ('Y', 'A'): -2, ('V', 'D'): -3, ('B', 'S'): 0, ('Y', 'Y'): 7,\n",
    "    ('G', 'N'): 0, ('E', 'C'): -4, ('Y', 'Q'): -1, ('Z', 'Z'): 4,\n",
    "    ('V', 'A'): 0, ('C', 'C'): 9, ('M', 'R'): -1, ('V', 'E'): -2,\n",
    "    ('T', 'N'): 0, ('P', 'P'): 7, ('V', 'I'): 3, ('V', 'S'): -2,\n",
    "    ('Z', 'P'): -1, ('V', 'M'): 1, ('T', 'F'): -2, ('V', 'Q'): -2,\n",
    "    ('K', 'K'): 5, ('P', 'D'): -1, ('I', 'H'): -3, ('I', 'D'): -3,\n",
    "    ('T', 'R'): -1, ('P', 'L'): -3, ('K', 'G'): -2, ('M', 'N'): -2,\n",
    "    ('P', 'H'): -2, ('F', 'Q'): -3, ('Z', 'G'): -2, ('X', 'L'): -1,\n",
    "    ('T', 'M'): -1, ('Z', 'C'): -3, ('X', 'H'): -1, ('D', 'R'): -2,\n",
    "    ('B', 'W'): -4, ('X', 'D'): -1, ('Z', 'K'): 1, ('F', 'A'): -2,\n",
    "    ('Z', 'W'): -3, ('F', 'E'): -3, ('D', 'N'): 1, ('B', 'K'): 0,\n",
    "    ('X', 'X'): -1, ('F', 'I'): 0, ('B', 'G'): -1, ('X', 'T'): 0,\n",
    "    ('F', 'M'): 0, ('B', 'C'): -3, ('Z', 'I'): -3, ('Z', 'V'): -2,\n",
    "    ('S', 'S'): 4, ('L', 'Q'): -2, ('W', 'E'): -3, ('Q', 'R'): 1,\n",
    "    ('N', 'N'): 6, ('W', 'M'): -1, ('Q', 'C'): -3, ('W', 'I'): -3,\n",
    "    ('S', 'C'): -1, ('L', 'A'): -1, ('S', 'G'): 0, ('L', 'E'): -3,\n",
    "    ('W', 'Q'): -2, ('H', 'G'): -2, ('S', 'K'): 0, ('Q', 'N'): 0,\n",
    "    ('N', 'R'): 0, ('H', 'C'): -3, ('Y', 'N'): -2, ('G', 'Q'): -2,\n",
    "    ('Y', 'F'): 3, ('C', 'A'): 0, ('V', 'L'): 1, ('G', 'E'): -2,\n",
    "    ('G', 'A'): 0, ('K', 'R'): 2, ('E', 'D'): 2, ('Y', 'R'): -2,\n",
    "    ('M', 'Q'): 0, ('T', 'I'): -1, ('C', 'D'): -3, ('V', 'F'): -1,\n",
    "    ('T', 'A'): 0, ('T', 'P'): -1, ('B', 'P'): -2, ('T', 'E'): -1,\n",
    "    ('V', 'N'): -3, ('P', 'G'): -2, ('M', 'A'): -1, ('K', 'H'): -1,\n",
    "    ('V', 'R'): -3, ('P', 'C'): -3, ('M', 'E'): -2, ('K', 'L'): -2,\n",
    "    ('V', 'V'): 4, ('M', 'I'): 1, ('T', 'Q'): -1, ('I', 'G'): -4,\n",
    "    ('P', 'K'): -1, ('M', 'M'): 5, ('K', 'D'): -1, ('I', 'C'): -1,\n",
    "    ('Z', 'D'): 1, ('F', 'R'): -3, ('X', 'K'): -1, ('Q', 'D'): 0,\n",
    "    ('X', 'G'): -1, ('Z', 'L'): -3, ('X', 'C'): -2, ('Z', 'H'): 0,\n",
    "    ('B', 'L'): -4, ('B', 'H'): 0, ('F', 'F'): 6, ('X', 'W'): -2,\n",
    "    ('B', 'D'): 4, ('D', 'A'): -2, ('S', 'L'): -2, ('X', 'S'): 0,\n",
    "    ('F', 'N'): -3, ('S', 'R'): -1, ('W', 'D'): -4, ('V', 'Y'): -1,\n",
    "    ('W', 'L'): -2, ('H', 'R'): 0, ('W', 'H'): -2, ('H', 'N'): 1,\n",
    "    ('W', 'T'): -2, ('T', 'T'): 5, ('S', 'F'): -2, ('W', 'P'): -4,\n",
    "    ('L', 'D'): -4, ('B', 'I'): -3, ('L', 'H'): -3, ('S', 'N'): 1,\n",
    "    ('B', 'T'): -1, ('L', 'L'): 4, ('Y', 'K'): -2, ('E', 'Q'): 2,\n",
    "    ('Y', 'G'): -3, ('Z', 'S'): 0, ('Y', 'C'): -2, ('G', 'D'): -1,\n",
    "    ('B', 'V'): -3, ('E', 'A'): -1, ('Y', 'W'): 2, ('E', 'E'): 5,\n",
    "    ('Y', 'S'): -2, ('C', 'N'): -3, ('V', 'C'): -1, ('T', 'H'): -2,\n",
    "    ('P', 'R'): -2, ('V', 'G'): -3, ('T', 'L'): -1, ('V', 'K'): -2,\n",
    "    ('K', 'Q'): 1, ('R', 'A'): -1, ('I', 'R'): -3, ('T', 'D'): -1,\n",
    "    ('P', 'F'): -4, ('I', 'N'): -3, ('K', 'I'): -3, ('M', 'D'): -3,\n",
    "    ('V', 'W'): -3, ('W', 'W'): 11, ('M', 'H'): -2, ('P', 'N'): -2,\n",
    "    ('K', 'A'): -1, ('M', 'L'): 2, ('K', 'E'): 1, ('Z', 'E'): 4,\n",
    "    ('X', 'N'): -1, ('Z', 'A'): -1, ('Z', 'M'): -1, ('X', 'F'): -1,\n",
    "    ('K', 'C'): -3, ('B', 'Q'): 0, ('X', 'B'): -1, ('B', 'M'): -3,\n",
    "    ('F', 'C'): -2, ('Z', 'Q'): 3, ('X', 'Z'): -1, ('F', 'G'): -3,\n",
    "    ('B', 'E'): 1, ('X', 'V'): -1, ('F', 'K'): -3, ('B', 'A'): -2,\n",
    "    ('X', 'R'): -1, ('D', 'D'): 6, ('W', 'G'): -2, ('Z', 'F'): -3,\n",
    "    ('S', 'Q'): 0, ('W', 'C'): -2, ('W', 'K'): -3, ('H', 'Q'): 0,\n",
    "    ('L', 'C'): -1, ('W', 'N'): -4, ('S', 'A'): 1, ('L', 'G'): -4,\n",
    "    ('W', 'S'): -3, ('S', 'E'): 0, ('H', 'E'): 0, ('S', 'I'): -2,\n",
    "    ('H', 'A'): -2, ('S', 'M'): -1, ('Y', 'L'): -1, ('Y', 'H'): 2,\n",
    "    ('Y', 'D'): -3, ('E', 'R'): 0, ('X', 'P'): -2, ('G', 'G'): 6,\n",
    "    ('G', 'C'): -3, ('E', 'N'): 0, ('Y', 'T'): -2, ('Y', 'P'): -3,\n",
    "    ('T', 'K'): -1, ('A', 'A'): 4, ('P', 'Q'): -1, ('T', 'C'): -1,\n",
    "    ('V', 'H'): -3, ('T', 'G'): -2, ('I', 'Q'): -3, ('Z', 'T'): -1,\n",
    "    ('C', 'R'): -3, ('V', 'P'): -2, ('P', 'E'): -1, ('M', 'C'): -1,\n",
    "    ('K', 'N'): 0, ('I', 'I'): 4, ('P', 'A'): -1, ('M', 'G'): -3,\n",
    "    ('T', 'S'): 1, ('I', 'E'): -3, ('P', 'M'): -2, ('M', 'K'): -1,\n",
    "    ('I', 'A'): -1, ('P', 'I'): -3, ('R', 'R'): 5, ('X', 'M'): -1,\n",
    "    ('L', 'I'): 2, ('X', 'I'): -1, ('Z', 'B'): 1, ('X', 'E'): -1,\n",
    "    ('Z', 'N'): 0, ('X', 'A'): 0, ('B', 'R'): -1, ('B', 'N'): 3,\n",
    "    ('F', 'D'): -3, ('X', 'Y'): -1, ('Z', 'R'): 0, ('F', 'H'): -1,\n",
    "    ('B', 'F'): -3, ('F', 'L'): 0, ('X', 'Q'): -1, ('B', 'B'): 4\n",
    "}\n",
    "#custom entries to the matrix\n",
    "pairs=list(blosum62.keys())\n",
    "singles=[]\n",
    "for pair in pairs:\n",
    "    blosum62[(pair[1],pair[0])]=blosum62[pair]\n",
    "    singles.append(pair[0])\n",
    "    singles.append(pair[1])\n",
    "singles=list(set(singles))\n",
    "for s in singles: #gap-substitution = -11\n",
    "    blosum62[('-',s)]=-11\n",
    "    blosum62[(s,'-')]=-11\n",
    "    blosum62[('.',s)]=-11\n",
    "    blosum62[(s,'.')]=-11\n",
    "    blosum62[(s,'O')]=0\n",
    "    blosum62[(s,'U')]=0\n",
    "    blosum62[('O',s)]=0\n",
    "    blosum62[('U',s)]=0\n",
    "blosum62[('.','.')]=0\n",
    "blosum62[('-','-')]=0\n",
    "blosum62[('.','-')]=0\n",
    "blosum62[('-','.')]=0\n",
    "blosum62[('O','O')]=10\n",
    "blosum62[('U','U')]=10\n",
    "blosum62[('O','U')]=0\n",
    "blosum62[('U','0')]=0\n",
    "blosum62[('O','-')]=-11\n",
    "blosum62[('U','-')]=-11\n",
    "blosum62[('-','O')]=-11\n",
    "blosum62[('-','U')]=-11\n",
    "blosum62[('O','.')]=-11\n",
    "blosum62[('U','.')]=-11\n",
    "blosum62[('.','O')]=-11\n",
    "blosum62[('.','U')]=-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blosum62[('O','-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17772\n"
     ]
    }
   ],
   "source": [
    "cluster_dir=os.path.join(basedir,'pfam_cdhit_clusters906030/')\n",
    "cluster_files=os.listdir(cluster_dir)\n",
    "print(len(cluster_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How to collect MSA from Pfam\n",
    "Parse each Pfam file and get sequence on the fly\n",
    "\"\"\"\n",
    "pfam_dir='/data/saturn/a/hlim/Pfam/Pfam/' #.aln as extension\n",
    "#=GC seq_cons (consensus sequence from all family members; used in case sub-clusters are not sufficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pfam_msa(pfamid):\n",
    "    pfam_msa={}\n",
    "    pfam_accession={}\n",
    "    with codecs.open(os.path.join(pfam_dir,pfamid+'.aln'),'r',encoding='utf-8', errors='replace') as inf:\n",
    "        for line in inf:\n",
    "            line=line.strip().split()\n",
    "            if len(line)<2:\n",
    "                continue\n",
    "            if line[0].startswith(\"#\"):\n",
    "                if line[0]==\"#=GS\":\n",
    "                    if line[2]==\"AC\":\n",
    "                        #=GS U5QJ87_9CYAN/28-322        AC U5QJ87.1\n",
    "                        seqid=line[1]\n",
    "                        uni=line[3]\n",
    "                        pfam_accession[seqid]=uni\n",
    "                elif line[0]==\"#=GC\":\n",
    "                    #=GC seq_cons\n",
    "                    pfam_msa['consensus']=line[2]\n",
    "            elif line[0].startswith('/'):\n",
    "                break\n",
    "            else:\n",
    "                seqid=line[0]\n",
    "                aligned_seq=line[1]\n",
    "                pfam_msa[seqid]=aligned_seq\n",
    "    return pfam_msa, pfam_accession\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conservation(x):\n",
    "    #x: (column_residues, i) where i is the column index\n",
    "    # column_residues: list of amino acids for i-the column in the alignment\n",
    "    #output: (score,i) , return i again for multiproc purpose\n",
    "    \n",
    "    residues = x[0]\n",
    "    i = x[1]\n",
    "    score = 0\n",
    "    for j,res1 in enumerate(residues):\n",
    "        for k,res2 in enumerate(residues):\n",
    "            if j<=k:\n",
    "                continue\n",
    "            score+=blosum62[(res1.upper(),res2.upper())]\n",
    "    return (score,i)\n",
    "\n",
    "def select_positions_by_subcluster_consensus_singleproc(seqlist,max_seq_len):\n",
    "    #input: seqlist=['ac-de','a--de','accde','ad-de','accee'], max_seq_len=3\n",
    "    #output: [0,3,4]\n",
    "    consensus_scores=[0.0]*len(seqlist[0])\n",
    "    \n",
    "    inputs=[] #list of (column_residues, i) where i is the column index\n",
    "    seqlist_clear=[]\n",
    "    for seq in seqlist:\n",
    "        if len(seq)<len(seqlist[0]):\n",
    "            continue\n",
    "        else:\n",
    "            seqlist_clear.append(seq)\n",
    "    seqlist=seqlist_clear\n",
    "    for i in range(len(seqlist[0])):\n",
    "        \n",
    "        column_residues=[seq[i] for seq in seqlist]\n",
    "        inputs.append((column_residues,i))\n",
    "    for inp in inputs:\n",
    "        s,i=calculate_conservation(inp)\n",
    "        consensus_scores[i]=s\n",
    "    selected_positions=sorted(np.argsort(consensus_scores)[::-1][:max_seq_len])\n",
    "    return selected_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_positions_by_subcluster_consensus_multiproc(seqlist,max_seq_len,ncpu=8):\n",
    "    #input: seqlist=['ac-de','a--de','accde','ad-de','accee'], max_seq_len=3\n",
    "    #output: [0,3,4]\n",
    "    #use ncpu-processes\n",
    "    consensus_scores=[0.0]*len(seqlist[0])\n",
    "    inputs=[] #list of (column_residues, i) where i is the column index\n",
    "    for i in range(len(seqlist[0])):\n",
    "        column_residues=[seq[i] for seq in seqlist]\n",
    "        inputs.append((column_residues,i))\n",
    "    outputs=[]\n",
    "    with Pool(ncpu) as pool:\n",
    "        for res in pool.imap_unordered(calculate_conservation,inputs):\n",
    "            outputs.append(res)\n",
    "    \n",
    "    for output in outputs:\n",
    "        consensus_scores[output[1]]=output[0]\n",
    "    selected_positions=sorted(np.argsort(consensus_scores)[::-1][:max_seq_len])\n",
    "    return selected_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_positions_by_default_consensus(consensus,max_seq_len):\n",
    "    hcpositions=[] #high-conserved\n",
    "    lcpositions=[] #low-conserved\n",
    "    cspositions=[] #conservative-substitution\n",
    "    inspositions=[] #insertion '.'\n",
    "    delpositions=[] #deletion '-'\n",
    "    for i,aa in enumerate(consensus):\n",
    "        if aa.isupper():\n",
    "            hcpositions.append(i)\n",
    "        elif aa.islower():\n",
    "            lcpositions.append(i)\n",
    "        elif aa=='+':\n",
    "            cspositions.append(i)\n",
    "        elif aa=='.':\n",
    "            inspositions.append(i)\n",
    "        elif aa=='-':\n",
    "            delpositions.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    selected_positions=hcpositions+lcpositions+cspositions\n",
    "    selected_positions=selected_positions[:max_seq_len]\n",
    "    selected_positions=sorted(selected_positions)\n",
    "    return selected_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 9, 13, 14, 15, 17, 20]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "dummy_sequences=[\"AACK-YD-KK--GFGK-MATH\",\n",
    "                 \"AACK-DD-LK--GFGK-MLTH\",\n",
    "                 \"AACK-DD-KK--GFGK-MLTH\",\n",
    "                 \"AACK-YD-KK--GFGK-MASH\",\n",
    "                 \"AACK-FD-KK--GYGK-MASH\",\n",
    "                 \"A-CK-YD-KK--GFGK-MLSH\",\n",
    "                 \"AACL-YD-KK--GFGK-MLSH\",\n",
    "                 \"ACCK-YD-LK---FGK-MATH\",\n",
    "                 \"ACSK-YD-LK---FGK-MATH\",\n",
    "                 \"ACSK-YD-LK---YGK-MATH\",\n",
    "                 \"ACSK-YD-LK---YGK-MATH\",\n",
    "                 \"ACSK-YD-LK---WGK-MATH\",\n",
    "                ]\n",
    "selected_singleproc=select_positions_by_subcluster_consensus_singleproc(dummy_sequences,8)\n",
    "selected_singleproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 9, 13, 14, 15, 17, 20]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "selected_multi=select_positions_by_subcluster_consensus_multiproc(dummy_sequences,8,ncpu=4)\n",
    "selected_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start computational load calculation using 48 cpus\n",
      "Single-family cluster-wise multiprocessing: 1000 Pfam families processed. 0.0330 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 2000 Pfam families processed. 0.0769 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 3000 Pfam families processed. 0.1220 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 4000 Pfam families processed. 0.1640 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 5000 Pfam families processed. 0.2101 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 6000 Pfam families processed. 0.2652 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 7000 Pfam families processed. 0.3218 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 8000 Pfam families processed. 0.3849 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 9000 Pfam families processed. 0.4483 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 10000 Pfam families processed. 0.4970 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 11000 Pfam families processed. 0.5455 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 12000 Pfam families processed. 0.6082 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 13000 Pfam families processed. 0.6676 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 14000 Pfam families processed. 0.7314 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 15000 Pfam families processed. 0.7890 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 16000 Pfam families processed. 0.8422 minutes elapsed so far...\n",
      "Single-family cluster-wise multiprocessing: 17000 Pfam families processed. 0.8917 minutes elapsed so far...\n"
     ]
    }
   ],
   "source": [
    "pfam_computational_load={} #key: pfamid, value: total number of calculation\n",
    "pfam_num_clusters={} #use to draw histogram\n",
    "cluster_members=[] #use to draw histogram\n",
    "\n",
    "def compute_computational_load(x):\n",
    "\n",
    "    cluster_dir = x[0]\n",
    "    pfamid = x[1]\n",
    "    pfam_clusters={}\n",
    "    pfam_msa, pfam_accession=collect_pfam_msa(pfamid)\n",
    "    with open(os.path.join(cluster_dir,pfamid+'.clstr'),'r',encoding=\"utf-8\") as inf:\n",
    "        current_cluster='Cluster 0'\n",
    "        for line in inf:\n",
    "            if line.startswith('>'):\n",
    "                current_cluster=line.replace('>','')\n",
    "                pfam_clusters[current_cluster]=[]\n",
    "                continue\n",
    "            seqid=line.strip().split('>')[1].split('|')[0]\n",
    "            pfam_clusters[current_cluster].append(seqid)\n",
    "        seqlen=len(pfam_msa['consensus'])\n",
    "        npairs=0\n",
    "        for cl in pfam_clusters.keys():\n",
    "            nc=len(pfam_clusters[cl])\n",
    "            npairs += nc*(nc-1)/2\n",
    "            cluster_members.append(nc)\n",
    "    return pfamid, len(pfam_clusters), npairs*seqlen\n",
    "    \n",
    "inputs1=[]\n",
    "for c in cluster_files:\n",
    "    pfamid=c.replace('.clstr','')\n",
    "    inputs1.append((cluster_dir,pfamid))\n",
    "\n",
    "print(\"Start computational load calculation using {} cpus\".format(ncpus))\n",
    "outputs=[]\n",
    "since=time.time()\n",
    "with Pool(ncpus) as pool:\n",
    "    num_families_processed=0\n",
    "    for res in pool.imap_unordered(compute_computational_load,inputs1):\n",
    "        num_families_processed+=1\n",
    "        outputs.append(res)\n",
    "        if num_families_processed%1000 == 0:\n",
    "            elapsed_part=time.time()-since\n",
    "            print(\"Single-family cluster-wise multiprocessing: {} Pfam families processed. {:.4f} minutes elapsed so far...\".format(\n",
    "                num_families_processed,elapsed_part/60.0))\n",
    "\n",
    "for out in outputs:\n",
    "    pfam_num_clusters[out[0]]=out[1]\n",
    "    pfam_computational_load[out[0]]=out[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4927442384622.0 82379799132.0\n"
     ]
    }
   ],
   "source": [
    "print(pfam_computational_load['PF00069.25'],pfam_computational_load['PF00001.21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PF00005.27', 9319161838840.0),\n",
       " ('PF00171.22', 6744077346012.0),\n",
       " ('PF00069.25', 4927442384622.0),\n",
       " ('PF00012.20', 1546974556032.0),\n",
       " ('PF00083.24', 1458139329660.0),\n",
       " ('PF13853.6', 1448720743698.0),\n",
       " ('PF00202.21', 1346821828277.0),\n",
       " ('PF07714.17', 1315717461994.0),\n",
       " ('PF13561.6', 1268251537581.0),\n",
       " ('PF02518.26', 1128529932800.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_families = sorted(pfam_computational_load.items(), key=lambda kv: kv[1], reverse=True)\n",
    "ordered_families[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PF12433.8', 0),\n",
       " ('PF05464.11', 0),\n",
       " ('PF17640.2', 0),\n",
       " ('PF07868.11', 0),\n",
       " ('PF09040.11', 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_families[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare for clustered pfam representations\n",
    "\"\"\"\n",
    "def preprocess_pfam(x):\n",
    "    pfamid=x[0]\n",
    "    mode=x[1]\n",
    "    pfam_clusters={} #key: cluster id, value: [seq ids]\n",
    "    pfam_file=os.path.join(pfam_dir,pfamid+'.aln')\n",
    "    pfam_msa, pfam_accession=collect_pfam_msa(pfamid)\n",
    "    consensus=select_positions_by_default_consensus(pfam_msa['consensus'],max_seq_len)\n",
    "\n",
    "    all_singlets=open(os.path.join(basedir,'all_pfam_singlet_withID/'+pfamid),'w')\n",
    "    all_triplets=open(os.path.join(basedir,'all_pfam_triplet_withID/'+pfamid),'w')\n",
    "    clustered_singlets=open(os.path.join(basedir,'pfam_clustered_singlets/'+pfamid),'w')\n",
    "    clustered_triplets=open(os.path.join(basedir,'pfam_clustered_triplets/'+pfamid),'w')\n",
    "\n",
    "    with open(os.path.join(cluster_dir,pfamid+'.clstr'),'r') as inf:\n",
    "        current_cluster='Cluster 0'\n",
    "        for line in inf:\n",
    "            if line.startswith('>'):\n",
    "                current_cluster=line.replace('>','')\n",
    "                pfam_clusters[current_cluster]=[]\n",
    "                continue\n",
    "            seqid=line.strip().split('>')[1].split('|')[0]\n",
    "            pfam_clusters[current_cluster].append(seqid)\n",
    "    for cl in pfam_clusters.keys():\n",
    "        if len(pfam_clusters[cl])<minimum_cluster_size:\n",
    "            selected_positions=consensus\n",
    "        else:\n",
    "            seqlist=[pfam_msa[seqid] for seqid in pfam_clusters[cl]]\n",
    "            if mode=='single':\n",
    "                selected_positions=select_positions_by_subcluster_consensus_singleproc(seqlist,max_seq_len)\n",
    "            elif mode=='multi':\n",
    "                selected_positions=select_positions_by_subcluster_consensus_multiproc(seqlist,max_seq_len,ncpu=ncpus)\n",
    "            else:\n",
    "                selected_positions=select_positions_by_subcluster_consensus_singleproc(seqlist,max_seq_len)\n",
    "\n",
    "        if len(selected_positions)==0:\n",
    "            continue\n",
    "        valid_seqs = []\n",
    "        for seqid in pfam_clusters[cl]:\n",
    "            min_len=selected_positions[-1] + 1\n",
    "            if len(pfam_msa[seqid])<min_len:\n",
    "                continue\n",
    "            else:\n",
    "                valid_seqs.append(seqid)\n",
    "        \n",
    "        for seqid in valid_seqs:\n",
    "\n",
    "            singlets=[]\n",
    "            triplets=[]\n",
    "            for i in selected_positions:\n",
    "                if i==0:\n",
    "                    first=padchar\n",
    "                else:\n",
    "                    first=pfam_msa[seqid][i-1]\n",
    "                second=pfam_msa[seqid][i]\n",
    "                if (i+1) == len(pfam_msa[seqid]):\n",
    "                    third=padchar\n",
    "                else:\n",
    "                    third=pfam_msa[seqid][i+1]\n",
    "                singlets.append(pfam_msa[seqid][i].replace('.',padchar).replace('-',gapchar).lower())\n",
    "\n",
    "                triplet=''.join((first,second,third)).lower().replace('.',padchar).replace('-',gapchar)\n",
    "                triplets.append(triplet)\n",
    "            if len(set(singlets_dump).difference({'9','j','x'})):\n",
    "                #skip sequences having only gaps or unknowns\n",
    "                continue\n",
    "\n",
    "            sentence_singlet=' '.join(singlets)\n",
    "            sentence_triplet=' '.join(triplets)\n",
    "            \n",
    "            if seqid == pfam_clusters[cl][0]: #representative sequence for the cluster\n",
    "                #it is used for pretraining. No sequence ID in the file needed\n",
    "                clustered_singlets.write(sentence_singlet+\"\\n\")\n",
    "                clustered_triplets.write(sentence_triplet+\"\\n\")\n",
    "            all_singlets.write(seqid+'\\t'+pfam_accession[seqid]+'\\t'+sentence_singlet+'\\n')\n",
    "            all_triplets.write(seqid+'\\t'+pfam_accession[seqid]+'\\t'+sentence_triplet+'\\n')\n",
    "        \n",
    "    all_singlets.close()\n",
    "    all_triplets.close()\n",
    "    clustered_singlets.close()\n",
    "    clustered_triplets.close()\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlets_dump=['j','j','j','9','9','j','9','j']\n",
    "len(set(singlets_dump).difference({'9','j','x'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Sanity check\n",
    "    \"\"\"\n",
    "    pfamid=\"PF01486.17\"\n",
    "    mode=\"multi\"\n",
    "    pfam_clusters={} #key: cluster id, value: [seq ids]\n",
    "    pfam_file=os.path.join(pfam_dir,pfamid+'.aln')\n",
    "    pfam_msa, pfam_accession=collect_pfam_msa(pfamid)\n",
    "    consensus=select_positions_by_default_consensus(pfam_msa['consensus'],max_seq_len)\n",
    "    with open(os.path.join(cluster_dir,pfamid+'.clstr'),'r') as inf:\n",
    "        current_cluster='Cluster 0'\n",
    "        for line in inf:\n",
    "            if line.startswith('>'):\n",
    "                current_cluster=line.replace('>','')\n",
    "                pfam_clusters[current_cluster]=[]\n",
    "                continue\n",
    "            seqid=line.strip().split('>')[1].split('|')[0]\n",
    "            pfam_clusters[current_cluster].append(seqid)\n",
    "    for cl in pfam_clusters.keys():\n",
    "        if len(pfam_clusters[cl])<minimum_cluster_size:\n",
    "            selected_positions=consensus\n",
    "        else:\n",
    "            seqlist=[pfam_msa[seqid] for seqid in pfam_clusters[cl]]\n",
    "            if mode=='single':\n",
    "                selected_positions=select_positions_by_subcluster_consensus_singleproc(seqlist,max_seq_len)\n",
    "            elif mode=='multi':\n",
    "                selected_positions=select_positions_by_subcluster_consensus_multiproc(seqlist,max_seq_len,ncpu=ncpus)\n",
    "            else:\n",
    "                selected_positions=select_positions_by_subcluster_consensus_singleproc(seqlist,max_seq_len)\n",
    "\n",
    "        if len(selected_positions)==0:\n",
    "            continue\n",
    "        valid_seqs = []\n",
    "        for seqid in pfam_clusters[cl]:\n",
    "            min_len=selected_positions[-1] + 1\n",
    "            if len(pfam_msa[seqid])<min_len:\n",
    "                continue\n",
    "            else:\n",
    "                valid_seqs.append(seqid)\n",
    "        \n",
    "        #k=1\n",
    "        #print(selected_positions)\n",
    "        \n",
    "        for seqid in valid_seqs:\n",
    "            #print(pfam_msa[seqid])\n",
    "            #print([pfam_msa[seqid][p] for p in selected_positions])\n",
    "            singlets=[]\n",
    "            triplets=[]\n",
    "            for i in selected_positions:\n",
    "                if i==0:\n",
    "                    first=padchar\n",
    "                else:\n",
    "                    first=pfam_msa[seqid][i-1]\n",
    "                second=pfam_msa[seqid][i]\n",
    "                if (i+1) == len(pfam_msa[seqid]):\n",
    "                    third=padchar\n",
    "                else:\n",
    "                    third=pfam_msa[seqid][i+1]\n",
    "                singlets.append(pfam_msa[seqid][i].replace('.',padchar).replace('-',gapchar).lower())\n",
    "\n",
    "                triplet=''.join((first,second,third)).lower().replace('.',padchar).replace('-',gapchar)\n",
    "                triplets.append(triplet)\n",
    "            if len(singlets)<max_seq_len:\n",
    "                for i in range(max_seq_len-len(singlets)):\n",
    "                    singlets.append(gapchar)\n",
    "            if len(triplets)<max_seq_len:\n",
    "                for i in range(max_seq_len-len(triplets)):\n",
    "                    triplets.append(gapchar*3)\n",
    "            sentence_singlet=' '.join(singlets)\n",
    "            sentence_triplet=' '.join(triplets)\n",
    "            \n",
    "            #print(seqid+'\\t'+pfam_accession[seqid]+'\\t'+sentence_singlet+'\\n')\n",
    "            #print(seqid+'\\t'+pfam_accession[seqid]+'\\t'+sentence_triplet+'\\n')\n",
    "#             k+=1\n",
    "#             if k==3:\n",
    "#                 break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "cutline=300 #below this, multiprocess by families; after this, multiprocess by columns in single family\n",
    "\n",
    "since=time.time()\n",
    "for pfamid in ordered_families[:cutline]:\n",
    "    preprocess_pfam((pfamid[0],'multi'))\n",
    "    num_families_processed+=1\n",
    "    if num_families_processed%20 == 0:\n",
    "        elapsed_part=time.time()-since\n",
    "        print(\"{} Pfam families processed. {:.4f} minutes elapsed so far...\".format(num_families_processed,elapsed_part/60.0))\n",
    "elapsed=time.time()-since\n",
    "print(\"{:.4f} minutes for {} families\".format(elapsed/60.0, num_families_processed)) \n",
    "\n",
    "inputs1=[]\n",
    "for pfamid in ordered_families[cutline:]:\n",
    "    inputs1.append((pfamid[0],'single'))\n",
    "\n",
    "since=time.time()\n",
    "with Pool(ncpus) as pool:\n",
    "    num_families_processed=0\n",
    "    for res in pool.imap_unordered(preprocess_pfam,inputs1):\n",
    "        num_families_processed+=1\n",
    "        if num_families_processed%1000 == 0:\n",
    "            elapsed_part=time.time()-since\n",
    "            print(\"{} Pfam families processed. {:.4f} minutes elapsed so far...\".format(num_families_processed,elapsed_part/60.0))\n",
    "elapsed=time.time()-since\n",
    "print(\"{:.4f} minutes for {} families\".format(elapsed/60.0, num_families_processed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
